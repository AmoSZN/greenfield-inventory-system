#!/usr/bin/env python3
"""
Production Deployment Preparation Script
Prepares your inventory system for cloud deployment
"""

import os
import json
import shutil
import subprocess
import sys
from datetime import datetime

def create_production_files():
    """Create all necessary production files"""
    
    print("üöÄ PREPARING PRODUCTION DEPLOYMENT")
    print("=" * 50)
    
    # 1. Create requirements.txt
    print("üì¶ Creating requirements.txt...")
    requirements = """
Flask==3.0.0
requests==2.31.0
aiohttp==3.9.1
python-dotenv==1.0.0
waitress==2.1.2
gunicorn==21.2.0
""".strip()
    
    with open('requirements.txt', 'w') as f:
        f.write(requirements)
    print("   ‚úÖ requirements.txt created")
    
    # 2. Create production configuration
    print("‚öôÔ∏è Creating production configuration...")
    
    production_config = """
import os
from datetime import timedelta

class ProductionConfig:
    # Flask Configuration
    SECRET_KEY = os.environ.get('SECRET_KEY', 'your-secret-key-change-this')
    DEBUG = False
    TESTING = False
    
    # Database Configuration
    DATABASE_URL = os.environ.get('DATABASE_URL', 'sqlite:///Data/inventory.db')
    
    # Paradigm ERP Configuration
    PARADIGM_API_KEY = os.environ.get('PARADIGM_API_KEY', 'nVPsQFBteV&GEd7*8n0%RliVjksag8')
    PARADIGM_USERNAME = os.environ.get('PARADIGM_USERNAME', 'web_admin')
    PARADIGM_PASSWORD = os.environ.get('PARADIGM_PASSWORD', 'ChangeMe#123!')
    PARADIGM_BASE_URL = os.environ.get('PARADIGM_BASE_URL', 'https://greenfieldapi.para-apps.com')
    
    # Performance Configuration
    MAX_CONTENT_LENGTH = 16 * 1024 * 1024  # 16MB max file size
    PERMANENT_SESSION_LIFETIME = timedelta(hours=24)
    
    # Security Configuration
    SESSION_COOKIE_SECURE = True
    SESSION_COOKIE_HTTPONLY = True
    SESSION_COOKIE_SAMESITE = 'Lax'
    
    # Logging Configuration
    LOG_LEVEL = os.environ.get('LOG_LEVEL', 'INFO')
    LOG_FILE = os.environ.get('LOG_FILE', 'production.log')
""".strip()
    
    with open('production_config.py', 'w') as f:
        f.write(production_config)
    print("   ‚úÖ production_config.py created")
    
    # 3. Create production WSGI entry point
    print("üåê Creating production WSGI server...")
    
    wsgi_content = """
#!/usr/bin/env python3
import os
import sys
import logging
from waitress import serve

# Add current directory to path
sys.path.insert(0, os.path.dirname(__file__))

# Import your Flask app
from inventory_system_24_7 import app

# Configure production logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('production.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

# Production configuration
app.config.from_object('production_config.ProductionConfig')

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8000))
    print(f"üöÄ Starting production server on port {port}")
    
    # Use Waitress WSGI server for production
    serve(
        app,
        host='0.0.0.0',
        port=port,
        threads=6,
        cleanup_interval=30,
        channel_timeout=120,
        max_request_body_size=1073741824  # 1GB
    )
""".strip()
    
    with open('wsgi.py', 'w') as f:
        f.write(wsgi_content)
    print("   ‚úÖ wsgi.py created")
    
    # 4. Create Docker configuration (optional)
    print("üê≥ Creating Docker configuration...")
    
    dockerfile = """
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \\
    gcc \\
    && rm -rf /var/lib/apt/lists/*

# Copy requirements first for better caching
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create data directory
RUN mkdir -p Data

# Expose port
EXPOSE 8000

# Run the application
CMD ["python", "wsgi.py"]
""".strip()
    
    with open('Dockerfile', 'w') as f:
        f.write(dockerfile)
    print("   ‚úÖ Dockerfile created")
    
    # 5. Create environment variables template
    print("üîê Creating environment variables...")
    
    env_template = """
# Production Environment Variables
SECRET_KEY=your-super-secret-key-change-this-in-production
DEBUG=False
LOG_LEVEL=INFO

# Paradigm ERP Configuration
PARADIGM_API_KEY=nVPsQFBteV&GEd7*8n0%RliVjksag8
PARADIGM_USERNAME=web_admin
PARADIGM_PASSWORD=ChangeMe#123!
PARADIGM_BASE_URL=https://greenfieldapi.para-apps.com

# Database Configuration (SQLite by default)
DATABASE_URL=sqlite:///Data/inventory.db

# Server Configuration
PORT=8000
WORKERS=4
""".strip()
    
    with open('.env.production', 'w') as f:
        f.write(env_template)
    print("   ‚úÖ .env.production created")
    
    # 6. Create deployment scripts
    print("üìú Creating deployment scripts...")
    
    # DigitalOcean deployment script
    do_deploy = """
#!/bin/bash
echo "üöÄ Deploying to DigitalOcean..."

# Install doctl (DigitalOcean CLI)
if ! command -v doctl &> /dev/null; then
    echo "Installing DigitalOcean CLI..."
    curl -sL https://github.com/digitalocean/doctl/releases/download/v1.98.0/doctl-1.98.0-windows-amd64.zip -o doctl.zip
    unzip doctl.zip
    mv doctl.exe /usr/local/bin/
fi

# Authenticate with DigitalOcean (you'll need to provide your API token)
echo "Please authenticate with DigitalOcean:"
echo "1. Go to https://cloud.digitalocean.com/account/api/tokens"
echo "2. Create a new personal access token"
echo "3. Run: doctl auth init"
echo "4. Enter your token when prompted"

echo "After authentication, run:"
echo "doctl apps create --spec digitalocean-app.yaml"
""".strip()
    
    with open('deploy_digitalocean.sh', 'w') as f:
        f.write(do_deploy)
    
    # DigitalOcean app specification
    do_spec = """
name: greenfield-inventory-system
services:
- name: web
  source_dir: /
  github:
    repo: your-username/greenfield-inventory-system
    branch: main
  run_command: python wsgi.py
  environment_slug: python
  instance_count: 1
  instance_size_slug: basic-xxs
  http_port: 8000
  routes:
  - path: /
  health_check:
    http_path: /api/stats
  envs:
  - key: SECRET_KEY
    value: your-secret-key-change-this
  - key: DEBUG
    value: "False"
  - key: PARADIGM_API_KEY
    value: nVPsQFBteV&GEd7*8n0%RliVjksag8
  - key: PARADIGM_USERNAME  
    value: web_admin
  - key: PARADIGM_PASSWORD
    value: ChangeMe#123!
  - key: PARADIGM_BASE_URL
    value: https://greenfieldapi.para-apps.com
""".strip()
    
    with open('digitalocean-app.yaml', 'w') as f:
        f.write(do_spec)
    
    print("   ‚úÖ Deployment scripts created")
    
    # 7. Create health check endpoint
    print("üè• Adding health check endpoint...")
    
    # We'll add this to the main app later
    health_check = '''
@app.route('/health')
def health_check():
    """Health check endpoint for production monitoring"""
    try:
        # Check database connection
        conn = sqlite3.connect('Data/inventory.db')
        c = conn.cursor()
        c.execute('SELECT COUNT(*) FROM items LIMIT 1')
        count = c.fetchone()[0]
        conn.close()
        
        # Check if we have inventory data
        if count > 0:
            return jsonify({
                'status': 'healthy',
                'timestamp': datetime.now().isoformat(),
                'items_count': count,
                'version': '2.0.0'
            }), 200
        else:
            return jsonify({
                'status': 'warning',
                'message': 'No inventory data loaded'
            }), 200
            
    except Exception as e:
        return jsonify({
            'status': 'unhealthy',
            'error': str(e)
        }), 500
'''
    
    # 8. Create production startup script
    print("üöÄ Creating startup script...")
    
    startup_script = """
@echo off
echo üöÄ Starting Greenfield Inventory System - Production Mode
echo ============================================================

REM Set production environment
set FLASK_ENV=production
set DEBUG=False

REM Load environment variables
if exist .env.production (
    echo Loading production environment variables...
    for /f "delims=" %%i in (.env.production) do set %%i
)

REM Start the production server
echo Starting production server...
python wsgi.py

pause
""".strip()
    
    with open('start_production.bat', 'w') as f:
        f.write(startup_script)
    print("   ‚úÖ start_production.bat created")
    
    # 9. Create monitoring script
    print("üìä Creating monitoring script...")
    
    monitoring_script = """
#!/usr/bin/env python3
import requests
import time
import smtplib
from email.mime.text import MimeText
from datetime import datetime

def monitor_system(url="http://localhost:8000"):
    '''Monitor system health and send alerts if needed'''
    
    while True:
        try:
            # Check health endpoint
            response = requests.get(f"{url}/health", timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                print(f"‚úÖ {datetime.now()}: System healthy - {data.get('items_count', 0)} items")
            else:
                print(f"‚ö†Ô∏è {datetime.now()}: System warning - Status {response.status_code}")
                
        except Exception as e:
            print(f"‚ùå {datetime.now()}: System error - {str(e)}")
            # Here you could add email/SMS alerts
            
        time.sleep(60)  # Check every minute

if __name__ == "__main__":
    print("üîç Starting system monitoring...")
    monitor_system()
""".strip()
    
    with open('monitor_system.py', 'w') as f:
        f.write(monitoring_script)
    print("   ‚úÖ monitor_system.py created")
    
    # 10. Create backup script
    print("üíæ Creating backup script...")
    
    backup_script = """
#!/usr/bin/env python3
import shutil
import os
from datetime import datetime
import zipfile

def create_backup():
    '''Create a backup of the system and data'''
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_name = f"greenfield_backup_{timestamp}"
    
    print(f"üì¶ Creating backup: {backup_name}")
    
    # Create backup directory
    os.makedirs(f"backups/{backup_name}", exist_ok=True)
    
    # Backup database
    if os.path.exists("Data/inventory.db"):
        shutil.copy2("Data/inventory.db", f"backups/{backup_name}/inventory.db")
        print("   ‚úÖ Database backed up")
    
    # Backup configuration files
    config_files = [
        "production_config.py",
        ".env.production", 
        "wsgi.py",
        "requirements.txt"
    ]
    
    for file in config_files:
        if os.path.exists(file):
            shutil.copy2(file, f"backups/{backup_name}/")
    
    # Create zip archive
    with zipfile.ZipFile(f"backups/{backup_name}.zip", 'w') as zipf:
        for root, dirs, files in os.walk(f"backups/{backup_name}"):
            for file in files:
                zipf.write(os.path.join(root, file))
    
    # Clean up temporary directory
    shutil.rmtree(f"backups/{backup_name}")
    
    print(f"‚úÖ Backup created: backups/{backup_name}.zip")

if __name__ == "__main__":
    os.makedirs("backups", exist_ok=True)
    create_backup()
""".strip()
    
    with open('create_backup.py', 'w') as f:
        f.write(backup_script)
    print("   ‚úÖ create_backup.py created")

def create_deployment_summary():
    """Create deployment summary and next steps"""
    
    print("\n" + "=" * 60)
    print("üéâ PRODUCTION DEPLOYMENT PREPARATION COMPLETE!")
    print("=" * 60)
    
    print("\nüìÅ FILES CREATED:")
    files = [
        "requirements.txt - Python dependencies",
        "production_config.py - Production configuration", 
        "wsgi.py - Production WSGI server",
        "Dockerfile - Docker containerization",
        ".env.production - Environment variables template",
        "deploy_digitalocean.sh - DigitalOcean deployment",
        "digitalocean-app.yaml - DigitalOcean app specification",
        "start_production.bat - Windows production startup",
        "monitor_system.py - System health monitoring",
        "create_backup.py - Automated backups"
    ]
    
    for file in files:
        print(f"   ‚úÖ {file}")
    
    print("\nüöÄ NEXT STEPS - CHOOSE YOUR DEPLOYMENT:")
    print("\n1Ô∏è‚É£ QUICK CLOUD DEPLOYMENT (Recommended - 30 min):")
    print("   ‚Ä¢ Go to https://cloud.digitalocean.com")
    print("   ‚Ä¢ Create account (get $200 free credit)")
    print("   ‚Ä¢ Create new App from GitHub")
    print("   ‚Ä¢ Upload your code and deploy!")
    
    print("\n2Ô∏è‚É£ LOCAL PRODUCTION TEST:")
    print("   ‚Ä¢ Run: start_production.bat")
    print("   ‚Ä¢ Test at: http://localhost:8000")
    print("   ‚Ä¢ Verify all features work")
    
    print("\n3Ô∏è‚É£ ENTERPRISE AZURE DEPLOYMENT:")
    print("   ‚Ä¢ Run: python azure_enterprise_setup.py")
    print("   ‚Ä¢ Follow Azure deployment guide")
    
    print("\nüìä YOUR SYSTEM WILL HAVE:")
    print("   ‚úÖ 24/7 uptime with auto-restart")
    print("   ‚úÖ SSL encryption (HTTPS)")
    print("   ‚úÖ Professional monitoring")
    print("   ‚úÖ Automated backups")
    print("   ‚úÖ Global accessibility")
    print("   ‚úÖ Mobile optimization")
    
    print(f"\nüåê ESTIMATED COSTS:")
    print("   ‚Ä¢ DigitalOcean: $12/month")
    print("   ‚Ä¢ Azure: $55/month") 
    print("   ‚Ä¢ Custom VPS: $5/month")
    
    print(f"\nüìû READY TO DEPLOY?")
    print("   Choose your option and follow the deployment guide!")
    print("   Your system will be live and accessible worldwide! üåç")

if __name__ == "__main__":
    try:
        create_production_files()
        create_deployment_summary()
        
        print(f"\nüéØ IMMEDIATE ACTION:")
        print("   1. Review the files created")
        print("   2. Choose your deployment option")
        print("   3. Follow PRODUCTION_DEPLOYMENT_GUIDE.md")
        print("   4. Your system will be live in 30 minutes! üöÄ")
        
    except Exception as e:
        print(f"‚ùå Error during preparation: {str(e)}")
        print("Please check the error and try again.")